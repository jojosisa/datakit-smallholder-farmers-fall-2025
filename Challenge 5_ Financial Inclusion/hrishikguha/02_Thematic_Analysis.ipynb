{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In the previous notebook (https://www.kaggle.com/code/hrishikguha/wefarm-embedding-similarity-scoring), I imported about 2000000 rows of the wefarm dataset, for initial analysis, and  computed embeddings and similarity scores with target financial phrases. In this notebook, I import the scored parquet file generated in the previous notebook, see what portion of the questions are financial, and finally, apply clustering techniques to group the financial questions thematically."
      ],
      "metadata": {
        "id": "fhUFfJJCWGb9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUchcgZzIor_"
      },
      "outputs": [],
      "source": [
        "import polars as pl\n",
        "import os\n",
        "\n",
        "# ---  CONFIGURATION AND LOADING ---\n",
        "FINAL_SCORED_PATH = \"all_10_parts_scored.parquet\"\n",
        "TEXT_COL = \"question_content\" # Column name for the question text\n",
        "\n",
        "print(f\"Attempting to load data from: {FINAL_SCORED_PATH}\")\n",
        "\n",
        "try:\n",
        "    # Load the scored data\n",
        "    scored_df_final = pl.read_parquet(FINAL_SCORED_PATH)\n",
        "    print(f\"âœ… Data loaded successfully. Total rows: {scored_df_final.shape[0]}\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ ERROR: Failed to load file. Ensure the file name is exactly 'all_10_parts_scored.parquet'\")\n",
        "    print(f\"Error details: {e}\")\n",
        "    # Stop execution if data cannot be loaded\n",
        "    raise\n",
        "\n",
        "# Filter down to only the questions classified as financial (is_financial == True)\n",
        "financial_questions_df = scored_df_final.filter(pl.col(\"is_financial\"))\n",
        "\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# --- QUANTITATIVE INSIGHTS: VOLUME AND CONFIDENCE ---\n",
        "\n",
        "total_questions = scored_df_final.shape[0]\n",
        "financial_count = financial_questions_df.shape[0]\n",
        "percent_financial = (financial_count / total_questions) * 100 if total_questions > 0 else 0\n",
        "\n",
        "# Calculate summary statistics for the confidence scores (sim_fin_max)\n",
        "confidence_summary = financial_questions_df.select(pl.col(\"sim_fin_max\")).describe()\n",
        "\n",
        "\n",
        "print(\"ðŸŽ¯ INITIAL INSIGHTS: VOLUME & CONFIDENCE\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"Total Questions Analyzed: {total_questions}\")\n",
        "print(f\"Questions Flagged as Financial: {financial_count} ({percent_financial:.2f}%)\")\n",
        "print(\"\\nConfidence Score (sim_fin_max) Summary for Financial Questions:\")\n",
        "print(confidence_summary)\n",
        "print(\"=\" * 60)\n",
        "\n",
        "\n",
        "# ---  QUALITATIVE INSIGHTS: TOP 10 THEMES ---\n",
        "\n",
        "print(\"\\nðŸ” QUALITATIVE INSIGHTS: TOP 10 HIGHEST CONFIDENCE QUESTIONS\")\n",
        "print(\"----------------------------------------------------------\")\n",
        "\n",
        "# Sort by the highest score and select the top 10\n",
        "top_hits_display = financial_questions_df.sort(\"sim_fin_max\", descending=True).head(10).select([\n",
        "    pl.col(TEXT_COL),\n",
        "    pl.col(\"sim_fin_max\").round(4).alias(\"Sim_Score\"),\n",
        "])\n",
        "\n",
        "# Use the corrected Polars configuration to ensure full text is printed\n",
        "with pl.Config(tbl_cols=-1, set_tbl_width_chars=500 ):\n",
        "    print(top_hits_display)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "# Filter down to financial questions and extract embeddings\n",
        "financial_df = scored_df_final.filter(pl.col(\"is_financial\"))\n",
        "if financial_df.shape[0] == 0:\n",
        "    raise ValueError(\"No financial questions found for clustering.\")\n",
        "\n",
        "financial_embeddings = np.stack(financial_df[\"embedding\"].to_list())\n",
        "print(f\"Loaded {financial_df.shape[0]} financial questions.\")"
      ],
      "metadata": {
        "id": "9eJbXIOISeqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---  OPTIMAL K DETERMINATION ---\n",
        "\n",
        "def find_optimal_k(embeddings, k_range=(2, 10)):\n",
        "    \"\"\"Calculates Inertia (Elbow) and Silhouette Score for a range of K values.\"\"\"\n",
        "    inertias = []\n",
        "    silhouette_scores = {}\n",
        "\n",
        "    k_values = range(k_range[0], k_range[1] + 1)\n",
        "\n",
        "    print(\"\\nCalculating Elbow and Silhouette scores for K in range 2-10...\")\n",
        "\n",
        "    for k in k_values:\n",
        "        # Run K-Means with the current K\n",
        "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "        clusters = kmeans.fit_predict(embeddings)\n",
        "\n",
        "        # 1. Elbow Method Metric (Inertia)\n",
        "        inertias.append(kmeans.inertia_)\n",
        "\n",
        "        # 2. Silhouette Score Metric (Measures density/separation)\n",
        "        # Skip Silhouette for K=1, as it requires at least two clusters\n",
        "        if k > 1:\n",
        "            score = silhouette_score(embeddings, clusters)\n",
        "            silhouette_scores[k] = score\n",
        "      # Plotting for visual determination\n",
        "    plt.figure(figsize=(10, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(k_values, inertias, marker='o')\n",
        "    plt.title('Elbow Method (Inertia)')\n",
        "    plt.xlabel('Number of Clusters (K)')\n",
        "    plt.ylabel('Inertia')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(list(silhouette_scores.keys()), list(silhouette_scores.values()), marker='o')\n",
        "    plt.title('Silhouette Score')\n",
        "    plt.xlabel('Number of Clusters (K)')\n",
        "    plt.ylabel('Silhouette Score')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Recommend the K with the highest Silhouette Score (most separated/dense clusters)\n",
        "    if silhouette_scores:\n",
        "        optimal_k = max(silhouette_scores, key=silhouette_scores.get)\n",
        "        print(f\"\\nRecommended K based on highest Silhouette Score: {optimal_k}\")\n",
        "        return optimal_k"
      ],
      "metadata": {
        "id": "rLnNlmjpTmJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute K determination and use the result\n",
        "K_CLUSTERS = find_optimal_k(financial_embeddings)"
      ],
      "metadata": {
        "id": "khEYLyMQT5ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---  FINAL CLUSTERING AND REPRODUCIBILITY FIX ---\n",
        "\n",
        "print(\"-\" * 60)\n",
        "#print(f\"Running final K-Means with K={K_CLUSTERS}...\")\n",
        "\n",
        "# Run the FINAL model with the determined K\n",
        "kmeans_final = KMeans(n_clusters=8, random_state=42, n_init=10)\n",
        "clusters = kmeans_final.fit_predict(financial_embeddings)\n",
        "\n",
        "# Add the cluster label back to the Polars DataFrame\n",
        "financial_df = financial_df.with_columns(\n",
        "    pl.Series(name=\"cluster_label\", values=clusters)\n",
        ")\n",
        "\n",
        "# FIX: Save the Cluster Centers for Reproducibility\n",
        "CLUSTER_CENTERS_PATH = \"cluster_centers_financial.npy\"\n",
        "np.save(CLUSTER_CENTERS_PATH, kmeans_final.cluster_centers_)\n",
        "print(f\"âœ… Cluster Centers saved for future prediction/reproducibility: {CLUSTER_CENTERS_PATH}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# ---  CLUSTER ANALYSIS AND QUALITY EVALUATION ---\n",
        "\n",
        "print(\"ðŸŽ¯ CLUSTER ANALYSIS: THEME DISCOVERY AND EVALUATION\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Calculate Cluster Quality Metrics\n",
        "final_silhouette_score = silhouette_score(financial_embeddings, clusters)\n",
        "\n",
        "print(f\"Total Questions Clustered: {financial_df.shape[0]}\")\n",
        "print(f\"Final Silhouette Score (Quality Metric): {final_silhouette_score:.4f} (Higher is Better)\")\n",
        "\n",
        "# Group by the new cluster label and count questions in each group\n",
        "cluster_counts = financial_df.group_by(\"cluster_label\").agg(\n",
        "    pl.count().alias(\"Count\"),\n",
        "    (pl.col(\"sim_fin_max\").mean()).round(4).alias(\"Avg_Sim_Score\")\n",
        ").sort(\"Count\", descending=True)\n",
        "\n",
        "print(\"\\nCluster Sizes and Average Confidence:\")\n",
        "print(cluster_counts)"
      ],
      "metadata": {
        "id": "amAL25ljUi0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The translation is not always great but I decided to list the full text of 10 questions from each cluster to understand the exact themes. This gives us a basic idea. The cluster themes go as follows: \"Saving\", \"Loans\", \"Cash Crops\", \"Government assistance, grants and subisidies\", \"Earnings from Farm\", \"Managing Farm Finance\", \"Farm Inputs\", and generic questions about which farming and poultry uses are the best. Going through example question text(listed below) for each cluster might be useful. I have not listed cluster no.1 due to poor readability and generic nature."
      ],
      "metadata": {
        "id": "rPsOzJaZOLzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURATION ---\n",
        "TARGET_CLUSTER = 0\n",
        "N_DISPLAY = 10\n",
        "TEXT_COL = \"question_content\"\n",
        "\n",
        "# Filter the DataFrame for the target cluster\n",
        "cluster_0_df = financial_df.filter(pl.col(\"cluster_label\") == TARGET_CLUSTER)\n",
        "\n",
        "# Sort by the highest similarity score (confidence) and select the top N_DISPLAY\n",
        "top_10_questions = cluster_0_df.sort(\"sim_fin_max\", descending=True).head(N_DISPLAY)\n",
        "\n",
        "# Extract the relevant data into a list of Python dictionaries\n",
        "questions_data = top_10_questions.select([TEXT_COL, \"sim_fin_max\", \"cluster_label\"]).to_dicts()\n",
        "\n",
        "# --- MANUAL PRINTING FOR FULL TEXT ---\n",
        "\n",
        "print(f\"\\n--- ðŸ¥‡ Top {N_DISPLAY} Questions for Cluster {TARGET_CLUSTER} ---\")\n",
        "print(f\"Total questions in Cluster {TARGET_CLUSTER}: {cluster_2_df.shape[0]}\")\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "# Manually print each question, ensuring full text is displayed\n",
        "for i, row in enumerate(questions_data):\n",
        "    # Print a separator for readability\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"| RANK: {i+1}\")\n",
        "    print(f\"| Score: {row['sim_fin_max']:.4f}\")\n",
        "    # Print the full question text\n",
        "    print(f\"| Question: {row[TEXT_COL]}\")\n",
        "\n",
        "print(\"=\" * 40)"
      ],
      "metadata": {
        "id": "WkZtqB0FHiT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURATION ---\n",
        "TARGET_CLUSTER = 2\n",
        "N_DISPLAY = 10\n",
        "TEXT_COL = \"question_content\"\n",
        "\n",
        "# Filter the DataFrame for the target cluster\n",
        "cluster_2_df = financial_df.filter(pl.col(\"cluster_label\") == TARGET_CLUSTER)\n",
        "\n",
        "# Sort by the highest similarity score (confidence) and select the top N_DISPLAY\n",
        "top_10_questions = cluster_2_df.sort(\"sim_fin_max\", descending=True).head(N_DISPLAY)\n",
        "\n",
        "# Extract the relevant data into a list of Python dictionaries\n",
        "questions_data = top_10_questions.select([TEXT_COL, \"sim_fin_max\", \"cluster_label\"]).to_dicts()\n",
        "\n",
        "# --- MANUAL PRINTING FOR FULL TEXT ---\n",
        "\n",
        "print(f\"\\n--- ðŸ¥‡ Top {N_DISPLAY} Questions for Cluster {TARGET_CLUSTER} ---\")\n",
        "print(f\"Total questions in Cluster {TARGET_CLUSTER}: {cluster_2_df.shape[0]}\")\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "# Manually print each question, ensuring full text is displayed\n",
        "for i, row in enumerate(questions_data):\n",
        "    # Print a separator for readability\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"| RANK: {i+1}\")\n",
        "    print(f\"| Score: {row['sim_fin_max']:.4f}\")\n",
        "    # Print the full question text\n",
        "    print(f\"| Question: {row[TEXT_COL]}\")\n",
        "\n",
        "print(\"=\" * 40)"
      ],
      "metadata": {
        "id": "tlCa5ZWYHcNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURATION ---\n",
        "TARGET_CLUSTER = 3\n",
        "N_DISPLAY = 10\n",
        "TEXT_COL = \"question_content\"\n",
        "\n",
        "# Filter the DataFrame for the target cluster\n",
        "cluster_3_df = financial_df.filter(pl.col(\"cluster_label\") == TARGET_CLUSTER)\n",
        "\n",
        "# Sort by the highest similarity score (confidence) and select the top N_DISPLAY\n",
        "top_10_questions = cluster_3_df.sort(\"sim_fin_max\", descending=True).head(N_DISPLAY)\n",
        "\n",
        "# Extract the relevant data into a list of Python dictionaries\n",
        "questions_data = top_10_questions.select([TEXT_COL, \"sim_fin_max\", \"cluster_label\"]).to_dicts()\n",
        "\n",
        "# --- MANUAL PRINTING FOR FULL TEXT ---\n",
        "\n",
        "print(f\"\\n--- ðŸ¥‡ Top {N_DISPLAY} Questions for Cluster {TARGET_CLUSTER} ---\")\n",
        "print(f\"Total questions in Cluster {TARGET_CLUSTER}: {cluster_2_df.shape[0]}\")\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "# Manually print each question, ensuring full text is displayed\n",
        "for i, row in enumerate(questions_data):\n",
        "    # Print a separator for readability\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"| RANK: {i+1}\")\n",
        "    print(f\"| Score: {row['sim_fin_max']:.4f}\")\n",
        "    # Print the full question text\n",
        "    print(f\"| Question: {row[TEXT_COL]}\")\n",
        "\n",
        "print(\"=\" * 40)"
      ],
      "metadata": {
        "id": "OjkWT3MtHZZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURATION ---\n",
        "TARGET_CLUSTER = 4\n",
        "N_DISPLAY = 10\n",
        "TEXT_COL = \"question_content\"\n",
        "\n",
        "# Filter the DataFrame for the target cluster\n",
        "cluster_4_df = financial_df.filter(pl.col(\"cluster_label\") == TARGET_CLUSTER)\n",
        "\n",
        "# Sort by the highest similarity score (confidence) and select the top N_DISPLAY\n",
        "top_10_questions = cluster_4_df.sort(\"sim_fin_max\", descending=True).head(N_DISPLAY)\n",
        "\n",
        "# Extract the relevant data into a list of Python dictionaries\n",
        "questions_data = top_10_questions.select([TEXT_COL, \"sim_fin_max\", \"cluster_label\"]).to_dicts()\n",
        "\n",
        "# --- MANUAL PRINTING FOR FULL TEXT ---\n",
        "\n",
        "print(f\"\\n--- ðŸ¥‡ Top {N_DISPLAY} Questions for Cluster {TARGET_CLUSTER} ---\")\n",
        "print(f\"Total questions in Cluster {TARGET_CLUSTER}: {cluster_2_df.shape[0]}\")\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "# Manually print each question, ensuring full text is displayed\n",
        "for i, row in enumerate(questions_data):\n",
        "    # Print a separator for readability\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"| RANK: {i+1}\")\n",
        "    print(f\"| Score: {row['sim_fin_max']:.4f}\")\n",
        "    # Print the full question text\n",
        "    print(f\"| Question: {row[TEXT_COL]}\")\n",
        "\n",
        "print(\"=\" * 40)"
      ],
      "metadata": {
        "id": "kqNANrGJHVgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURATION ---\n",
        "TARGET_CLUSTER = 5\n",
        "N_DISPLAY = 10\n",
        "TEXT_COL = \"question_content\"\n",
        "\n",
        "# Filter the DataFrame for the target cluster\n",
        "cluster_5_df = financial_df.filter(pl.col(\"cluster_label\") == TARGET_CLUSTER)\n",
        "\n",
        "# Sort by the highest similarity score (confidence) and select the top N_DISPLAY\n",
        "top_10_questions = cluster_5_df.sort(\"sim_fin_max\", descending=True).head(N_DISPLAY)\n",
        "\n",
        "# Extract the relevant data into a list of Python dictionaries\n",
        "questions_data = top_10_questions.select([TEXT_COL, \"sim_fin_max\", \"cluster_label\"]).to_dicts()\n",
        "\n",
        "# --- MANUAL PRINTING FOR FULL TEXT ---\n",
        "\n",
        "print(f\"\\n--- ðŸ¥‡ Top {N_DISPLAY} Questions for Cluster {TARGET_CLUSTER} ---\")\n",
        "print(f\"Total questions in Cluster {TARGET_CLUSTER}: {cluster_2_df.shape[0]}\")\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "# Manually print each question, ensuring full text is displayed\n",
        "for i, row in enumerate(questions_data):\n",
        "    # Print a separator for readability\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"| RANK: {i+1}\")\n",
        "    print(f\"| Score: {row['sim_fin_max']:.4f}\")\n",
        "    # Print the full question text\n",
        "    print(f\"| Question: {row[TEXT_COL]}\")\n",
        "\n",
        "print(\"=\" * 40)"
      ],
      "metadata": {
        "id": "0k7owCD3HRMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURATION ---\n",
        "TARGET_CLUSTER = 6\n",
        "N_DISPLAY = 10\n",
        "TEXT_COL = \"question_content\"\n",
        "\n",
        "# Filter the DataFrame for the target cluster\n",
        "cluster_6_df = financial_df.filter(pl.col(\"cluster_label\") == TARGET_CLUSTER)\n",
        "\n",
        "# Sort by the highest similarity score (confidence) and select the top N_DISPLAY\n",
        "top_10_questions = cluster_6_df.sort(\"sim_fin_max\", descending=True).head(N_DISPLAY)\n",
        "\n",
        "# Extract the relevant data into a list of Python dictionaries\n",
        "questions_data = top_10_questions.select([TEXT_COL, \"sim_fin_max\", \"cluster_label\"]).to_dicts()\n",
        "\n",
        "# --- MANUAL PRINTING FOR FULL TEXT ---\n",
        "\n",
        "print(f\"\\n--- ðŸ¥‡ Top {N_DISPLAY} Questions for Cluster {TARGET_CLUSTER} ---\")\n",
        "print(f\"Total questions in Cluster {TARGET_CLUSTER}: {cluster_2_df.shape[0]}\")\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "# Manually print each question, ensuring full text is displayed\n",
        "for i, row in enumerate(questions_data):\n",
        "    # Print a separator for readability\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"| RANK: {i+1}\")\n",
        "    print(f\"| Score: {row['sim_fin_max']:.4f}\")\n",
        "    # Print the full question text\n",
        "    print(f\"| Question: {row[TEXT_COL]}\")\n",
        "\n",
        "print(\"=\" * 40)"
      ],
      "metadata": {
        "id": "Y8vPWGc4HMuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CONFIGURATION ---\n",
        "TARGET_CLUSTER = 7\n",
        "N_DISPLAY = 10\n",
        "TEXT_COL = \"question_content\"\n",
        "\n",
        "# Filter the DataFrame for the target cluster\n",
        "cluster_7_df = financial_df.filter(pl.col(\"cluster_label\") == TARGET_CLUSTER)\n",
        "\n",
        "# Sort by the highest similarity score (confidence) and select the top N_DISPLAY\n",
        "top_10_questions = cluster_7_df.sort(\"sim_fin_max\", descending=True).head(N_DISPLAY)\n",
        "\n",
        "# Extract the relevant data into a list of Python dictionaries\n",
        "questions_data = top_10_questions.select([TEXT_COL, \"sim_fin_max\", \"cluster_label\"]).to_dicts()\n",
        "\n",
        "# --- MANUAL PRINTING FOR FULL TEXT ---\n",
        "\n",
        "print(f\"\\n--- ðŸ¥‡ Top {N_DISPLAY} Questions for Cluster {TARGET_CLUSTER} ---\")\n",
        "print(f\"Total questions in Cluster {TARGET_CLUSTER}: {cluster_2_df.shape[0]}\")\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "# Manually print each question, ensuring full text is displayed\n",
        "for i, row in enumerate(questions_data):\n",
        "    # Print a separator for readability\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"| RANK: {i+1}\")\n",
        "    print(f\"| Score: {row['sim_fin_max']:.4f}\")\n",
        "    # Print the full question text\n",
        "    print(f\"| Question: {row[TEXT_COL]}\")\n",
        "\n",
        "print(\"=\" * 40)"
      ],
      "metadata": {
        "id": "hp5r30WXZA6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DO69Y5GwZ040"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}